{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6887213,"sourceType":"datasetVersion","datasetId":3956380},{"sourceId":10314523,"sourceType":"datasetVersion","datasetId":6385522},{"sourceId":12468223,"sourceType":"datasetVersion","datasetId":7865904},{"sourceId":12479917,"sourceType":"datasetVersion","datasetId":7874430}],"dockerImageVersionId":30823,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport random\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:44:29.075616Z","iopub.execute_input":"2025-08-28T14:44:29.076007Z","iopub.status.idle":"2025-08-28T14:44:29.082806Z","shell.execute_reply.started":"2025-08-28T14:44:29.075978Z","shell.execute_reply":"2025-08-28T14:44:29.081705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from collections import Counter\n\n# def is_image_file(filename):\n#     \"\"\"Check if a file is an image based on its extension.\"\"\"\n#     valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}\n#     return any(filename.lower().endswith(ext) for ext in valid_extensions)\n\n# def find_top_classes(base_path, top_n=100):\n#     \"\"\"Find the top N classes with the most image files.\"\"\"\n#     class_image_count = {}\n\n#     for class_name in os.listdir(base_path):\n#         class_path = os.path.join(base_path, class_name)\n\n#         if os.path.isdir(class_path):  # Ensure it's a directory\n#             # Count image files in the class directory\n#             image_count = sum(\n#                 is_image_file(filename)\n#                 for filename in os.listdir(class_path)\n#             )\n#             class_image_count[class_name] = image_count\n\n#     # Get the top N classes\n#     top_classes = Counter(class_image_count).most_common(top_n)\n#     return top_classes\n\n# # Base path to the directory containing the 10,500 classes\n# base_directory = \"/kaggle/input/casia-webface/datasets\"\n\n# # Find the top 100 classes\n# top_50_classes = find_top_classes(base_directory, top_n=50)\n\n# # Print the results\n# print(\"Top 50 classes with the most images:\")\n# for rank, (class_name, count) in enumerate(top_50_classes, start=1):\n#     print(f\"{rank}. {class_name}: {count} images\")\n\n# with open('/kaggle/working/top100class.pkl', 'wb') as f:\n#     pickle.dump(top_50_classes, f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T14:26:53.247356Z","iopub.execute_input":"2024-12-27T14:26:53.247948Z","execution_failed":"2024-12-27T14:28:15.107Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom collections import defaultdict\nfrom pathlib import Path\n\n# Set of supported image file extensions\nIMAGE_EXTENSIONS = '.jpg'\n\ndef count_images_in_directory(base_dir):\n    \"\"\"\n    Traverse the base directory recursively and count image files in each subdirectory.\n    Returns a dictionary mapping directory paths to image counts.\n    \"\"\"\n    image_counts = defaultdict(int)\n    \n    for root, dirs, files in os.walk(base_dir):\n        count = sum(1 for f in files if Path(f).suffix.lower() == IMAGE_EXTENSIONS)\n        if count > 0:\n            image_counts[root] = count\n            \n    return image_counts\n\ndef get_top_image_dirs(base_dir, top_n=100):\n    \"\"\"\n    Returns the top_n directories under base_dir that contain the most image files.\n    \"\"\"\n    image_counts = count_images_in_directory(base_dir)\n    top_dirs = sorted(image_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n    return top_dirs\n\n# Example usage:\nbase_dir = '/kaggle/input/casia-webface/datasets'  # Replace with your path\ntop_100_classes = get_top_image_dirs(base_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:26:14.780759Z","iopub.execute_input":"2025-08-28T14:26:14.781058Z","iopub.status.idle":"2025-08-28T14:26:20.612378Z","shell.execute_reply.started":"2025-08-28T14:26:14.781035Z","shell.execute_reply":"2025-08-28T14:26:20.610955Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/input/d/seragehab/top100class/top100class.pkl', 'rb') as f:\n    top_100_classes = pickle.load(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:44:36.277828Z","iopub.execute_input":"2025-08-28T14:44:36.278198Z","iopub.status.idle":"2025-08-28T14:44:36.289214Z","shell.execute_reply.started":"2025-08-28T14:44:36.278171Z","shell.execute_reply":"2025-08-28T14:44:36.288451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display results in the notebook\nsum = 0\nfor i, (dir_path, count) in enumerate(top_100_classes, 1):\n    print(f\"{i:3}. {dir_path} --> {count} images\")\n    sum += count\nprint(f\"The total number of images in the top 100 classes is {sum}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T11:11:53.694276Z","iopub.execute_input":"2025-08-28T11:11:53.694714Z","iopub.status.idle":"2025-08-28T11:11:53.714287Z","shell.execute_reply.started":"2025-08-28T11:11:53.694679Z","shell.execute_reply":"2025-08-28T11:11:53.704651Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/working/top100class.pkl', 'wb') as f:\n    pickle.dump((top_100_classes), f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:14:38.757808Z","iopub.execute_input":"2025-08-28T14:14:38.758134Z","iopub.status.idle":"2025-08-28T14:14:38.762909Z","shell.execute_reply.started":"2025-08-28T14:14:38.758110Z","shell.execute_reply":"2025-08-28T14:14:38.762007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the base directory\nbase_dir = '/kaggle/input/casia-webface/datasets'\n\n# Initialize data and labels lists\ndata = []\nlables = []\n\n# Loop through each subdirectory (class) in the base directory\nfor class_name in top_100_classes[:50] :\n    class_dir = os.path.join(base_dir, str(class_name[0]))\n    if (top_100_classes.index(class_name) + 1)%10 == 0: print(f\"handling class number {top_100_classes.index(class_name) + 1}\")\n    # Check if it's a directory\n    if os.path.isdir(class_dir):\n        # Loop through each image in the class directory\n        for image_name in os.listdir(class_dir)[:200]:\n            image_path = os.path.join(class_dir, image_name)\n            # Load the image using OpenCV\n            image = cv2.imread(image_path)\n            image = cv2.resize(image , (112 , 112))\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            if image is not None:\n                # Append the image data and its label\n                data.append(image)\n                lables.append(class_name)\n\n# Convert lists to numpy arrays for further processing\ndata = np.array(data)\nlables = np.array(lables)\n\nwith open('/kaggle/working/data.pkl', 'wb') as f:\n    pickle.dump((data,lables), f)\n\n# Print summary\n# print(f\"Loaded {len(data)} images with labels: {set(labels)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:48:41.424763Z","iopub.execute_input":"2025-08-28T14:48:41.425062Z","iopub.status.idle":"2025-08-28T14:49:08.757381Z","shell.execute_reply.started":"2025-08-28T14:48:41.425039Z","shell.execute_reply":"2025-08-28T14:49:08.756398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## fokk mn ally ta7t dy ##\n \n","metadata":{}},{"cell_type":"code","source":"# Normalize images in batches and ensure float32\ndef normalize_images_per_image(images):\n    normalized_images = np.zeros_like(images, dtype=np.float32)\n    for i,image in enumerate(images):\n        mean = np.mean(image)\n        std = np.std(image)\n        normalized_images[i] = ( image - mean ) / std \n        if i%500==0:\n            print(i)\n    normalized_images =  normalized_images.astype(np.float32)\n    # print(normalized_images.shape)\n    return normalized_images  # Ensure float32\n\ndef normalize_images_in_batches(images, batch_size):\n    normalized_images = np.zeros_like(images, dtype=np.float32)\n    for i in range(0, len(images) ,batch_size):\n        images_batch = images[i:i+batch_size] if i+batch_size < len(images) else images[i:len(images)]\n        mean = np.mean(images_batch)\n        std = np.std(images_batch)\n        normalized_images_batch = ( images_batch - mean ) / std \n        normalized_images[i:i+len(images_batch)] = normalized_images_batch \n        if i%500==0:\n            print(i)\n    normalized_images =  normalized_images.astype(np.float32)\n    print(normalized_images.shape)\n    return normalized_images  # Ensure float32\n\n\n\n# Normalize images\nnormalized_images = normalize_images_in_batches(data,7000)\n\n\n\n\nwith open('/kaggle/working/normalized_images.pkl', 'wb') as f:\n    pickle.dump(normalized_images, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T11:25:01.179668Z","iopub.execute_input":"2025-08-28T11:25:01.180011Z","iopub.status.idle":"2025-08-28T11:25:09.975445Z","shell.execute_reply.started":"2025-08-28T11:25:01.179982Z","shell.execute_reply":"2025-08-28T11:25:09.974415Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(data.shape)\n\ntotal_samples = data.shape[0]\ntrain_size = int(0.7 * total_samples)\nval_size = int(0.15 * total_samples)\ntest_size = total_samples - train_size - val_size  # To ensure all samples are used\n\n# Shuffle data\nnp.random.seed(42)  # For reproducibility\nindices = np.random.permutation(total_samples)\n\n# Split the data\ntrain_indices = indices[-train_size:]\nval_indices = indices[:val_size]\ntest_indices = indices[val_size:val_size+test_size]\n\ntrain_data = data[train_indices]\nval_data = data[val_indices]\ntest_data = data[test_indices]\n\ntrain_lables = lables[train_indices]\nval_lables = lables[val_indices]\ntest_lables = lables[test_indices]\n\ntraining_mean = train_data.mean(axis=(0,1,2))\ntraining_std = train_data.std(axis=(0,1,2))\n\ntrain_data_norm = (train_data - training_mean)/ training_std\nval_data_norm = (val_data - training_mean)/ training_std\ntest_data_norm = (test_data - training_mean)/ training_std\n\nprint(train_data.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:49:21.244158Z","iopub.execute_input":"2025-08-28T14:49:21.244484Z","iopub.status.idle":"2025-08-28T14:49:32.986608Z","shell.execute_reply.started":"2025-08-28T14:49:21.244460Z","shell.execute_reply":"2025-08-28T14:49:32.985604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/working/data.pkl', 'rb') as f:\n    data,lables = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T11:33:47.569687Z","iopub.execute_input":"2025-08-28T11:33:47.569993Z","iopub.status.idle":"2025-08-28T11:33:47.858095Z","shell.execute_reply.started":"2025-08-28T11:33:47.569969Z","shell.execute_reply":"2025-08-28T11:33:47.857303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/working/normalized_images.pkl', 'rb') as f:\n    normalized_images = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T19:58:39.266271Z","iopub.execute_input":"2025-07-14T19:58:39.266596Z","iopub.status.idle":"2025-07-14T19:58:48.475196Z","shell.execute_reply.started":"2025-07-14T19:58:39.266571Z","shell.execute_reply":"2025-07-14T19:58:48.474418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with open('/kaggle/input/ci-milestone2/data.pkl', 'rb') as f:\n#     data,labels = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:27:42.556108Z","iopub.execute_input":"2024-12-27T17:27:42.556524Z","iopub.status.idle":"2024-12-27T17:27:42.998565Z","shell.execute_reply.started":"2024-12-27T17:27:42.556493Z","shell.execute_reply":"2024-12-27T17:27:42.997383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with open('/kaggle/input/ci-milestone2/normalized_images.pkl', 'rb') as f:\n#     normalized_images = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:27:44.133799Z","iopub.execute_input":"2024-12-27T17:27:44.134231Z","iopub.status.idle":"2024-12-27T17:27:45.793485Z","shell.execute_reply.started":"2024-12-27T17:27:44.134195Z","shell.execute_reply":"2024-12-27T17:27:45.792346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(training_std)\n# Randomly choose an image index to visualize\nsample_idx = np.random.choice(train_data.shape[0])\n\nsample_image = train_data[sample_idx]\n\nnormalized_sample_image = train_data_norm[sample_idx]\n# Compute min and max per channel\nc_min = normalized_sample_image.min(axis=(0,1), keepdims=True)\nc_max = normalized_sample_image.max(axis=(0,1), keepdims=True)\n\n# Scale each channel independently to [0,1]\nnormalized_sample_image = (normalized_sample_image - c_min) / (c_max - c_min + 1e-8)\n# normalized_sample_image = (normalized_sample_image - normalized_sample_image.min()) / (normalized_sample_image.max() - normalized_sample_image.min())\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))\nax[0].imshow(sample_image)\nax[0].set_title('Original Image')\nax[0].axis('off')\n\nax[1].imshow(normalized_sample_image)\nax[1].set_title('Normalized Image')\nax[1].axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:49:45.032279Z","iopub.execute_input":"2025-08-28T14:49:45.032641Z","iopub.status.idle":"2025-08-28T14:49:45.350532Z","shell.execute_reply.started":"2025-08-28T14:49:45.032611Z","shell.execute_reply":"2025-08-28T14:49:45.349506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate split sizes\n\n# total_samples = normalized_images.shape[0]\n# train_size = int(0.7 * total_samples)\n# val_size = int(0.15 * total_samples)\n# test_size = total_samples - train_size - val_size  # To ensure all samples are used\n\n# # Shuffle data\n# np.random.seed(42)  # For reproducibility\n# indices = np.random.permutation(total_samples)\n\n# # Split the data\n# train_indices = indices[-train_size:]\n# val_indices = indices[:val_size]\n# test_indices = indices[val_size:val_size+test_size]\n\n# train_data = normalized_images[train_indices]\n# val_data = normalized_images[val_indices]\n# test_data = normalized_images[test_indices]\n\n# Output shapes\nprint(\"Training data shape:\", train_data_norm.shape)\nprint(\"Validation data shape:\", val_data_norm.shape)\nprint(\"Testing data shape:\", test_data_norm.shape)\n\ndef generator():\n    for x, y in zip(train_data_norm, train_data_norm):\n        yield x, y\n\n\nbatch_size = 32\n# train_dataset = (\n#     tf.data.Dataset.from_tensor_slices((train_data, train_data))\n#     .batch(batch_size)\n#     .shuffle(1000)\n#     .prefetch(tf.data.AUTOTUNE)\n# )\n\ntrain_dataset = tf.data.Dataset.from_generator(\n    generator,\n    output_signature=(\n        tf.TensorSpec(shape=(112, 112, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(112, 112, 3), dtype=tf.float32),\n    )\n).batch(batch_size).shuffle(1000).cache().prefetch(tf.data.AUTOTUNE)\n\nval_dataset = (\n    tf.data.Dataset.from_tensor_slices((val_data_norm, val_data_norm))\n    .batch(batch_size)\n    .prefetch(tf.data.AUTOTUNE)\n)\n\ntest_dataset = (\n    tf.data.Dataset.from_tensor_slices((test_data_norm, test_data_norm))\n    .batch(batch_size)\n    .prefetch(tf.data.AUTOTUNE)\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:49:57.510164Z","iopub.execute_input":"2025-08-28T14:49:57.510490Z","iopub.status.idle":"2025-08-28T14:50:04.182399Z","shell.execute_reply.started":"2025-08-28T14:49:57.510465Z","shell.execute_reply":"2025-08-28T14:50:04.181728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convolutional Autoencoder model definition\ndef convolutional_autoencoder(input_shape):\n    print(f\"Input shape: {input_shape}\")\n    inputs = tf.keras.Input(shape=input_shape)\n\n    # Encoder\n    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n    # x = tf.keras.layers.Dropout(0.05)(x)  # Dropout after first block\n\n    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n    # x = tf.keras.layers.Dropout(0.05)(x)  # Dropout after second block\n\n    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n    # x = tf.keras.layers.Dropout(0.05)(x)  # Dropout after third block\n\n    # Latent space\n    latent_space = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name=\"latent_space\")(x)\n\n    # Decoder\n    x = tf.keras.layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(latent_space)\n    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n    # x = tf.keras.layers.Dropout(0.05)(x)\n\n    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n    # x = tf.keras.layers.Dropout(0.05)(x)\n\n    x = tf.keras.layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n    # x = tf.keras.layers.Dropout(0.05)(x)\n\n    outputs = tf.keras.layers.Conv2DTranspose(input_shape[-1], (3, 3), activation='linear', padding='same')(x)\n\n    autoencoder = tf.keras.Model(inputs, outputs, name=\"Convolutional_Autoencoder\")\n    encoder = tf.keras.Model(inputs, latent_space, name=\"Encoder\")\n\n    return autoencoder, encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:50:21.193533Z","iopub.execute_input":"2025-08-28T14:50:21.193911Z","iopub.status.idle":"2025-08-28T14:50:21.203635Z","shell.execute_reply.started":"2025-08-28T14:50:21.193879Z","shell.execute_reply":"2025-08-28T14:50:21.202666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = (112, 112, 3)\nconv_autoencoder, conv_encoder = convolutional_autoencoder(input_shape=input_shape)\nconv_autoencoder.compile(optimizer='Nadam', loss='mse')  # Mean squared error\n\n# Train the autoencoder\nepochs = 120\n_ = conv_autoencoder.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=epochs,\n    verbose=1\n)\n\n# Evaluate the model on the test set\ntest_loss = conv_autoencoder.evaluate(test_dataset)\nprint(f\"Test Loss: {test_loss:.4f}\")\nconv_autoencoder.save_weights(\"/kaggle/working/autoencoder.weights.h5\")\nprint(\"model weights are saved \")\n# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n\n# Save the history and test_loss objects\n# results = [\n#     conv_history , test_loss , test_accuracy\n# ]\n\n# Save the objects to a pickle file\n# with open('/kaggle/working/conv_results.pkl', 'wb') as f:\n#     pickle.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T14:50:27.823659Z","iopub.execute_input":"2025-08-28T14:50:27.823990Z","iopub.status.idle":"2025-08-28T15:02:25.507907Z","shell.execute_reply.started":"2025-08-28T14:50:27.823960Z","shell.execute_reply":"2025-08-28T15:02:25.507036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conv_autoencoder, _ = convolutional_autoencoder(input_shape=(112, 112, 3))\nconv_autoencoder.load_weights(\"/kaggle/working/autoencoder.weights.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T12:13:06.218912Z","iopub.execute_input":"2025-08-28T12:13:06.219260Z","iopub.status.idle":"2025-08-28T12:13:06.333139Z","shell.execute_reply.started":"2025-08-28T12:13:06.219232Z","shell.execute_reply":"2025-08-28T12:13:06.332199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Randomly choose an image index to visualize\nsample_idx = np.random.choice(data.shape[0])\nsample_image = data[sample_idx]\n\nnormalized_sample_image = normalized_images[sample_idx]\nnormalized_sample_image = (normalized_sample_image - normalized_sample_image.min()) / (normalized_sample_image.max() - normalized_sample_image.min())\n\n\n# Add batch dimension before passing to the model\ninput_image = np.expand_dims(sample_image, axis=0)  # shape becomes (1, H, W, C)\n\n# Predict the reconstructed image\npredicted_image = conv_autoencoder.predict(input_image)[0]  # Remove batch dimension\nprint(predicted_image.shape)\npredicted_image = (predicted_image - np.min(predicted_image)) / (np.max(predicted_image) - np.min(predicted_image))\n\n# Plot original vs. reconstructed image\nfig, ax = plt.subplots(1, 3, figsize=(12, 6))\n\nax[0].imshow(sample_image)\nax[0].set_title('Original Image')\nax[0].axis('off')\n\nax[1].imshow(normalized_sample_image)\nax[1].set_title('Normalized Image')\nax[1].axis('off')\n\nax[2].imshow(predicted_image)\nax[2].set_title('Reconstructed Image')\nax[2].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T15:04:03.166127Z","iopub.execute_input":"2025-08-28T15:04:03.166479Z","iopub.status.idle":"2025-08-28T15:04:03.186948Z","shell.execute_reply.started":"2025-08-28T15:04:03.166447Z","shell.execute_reply":"2025-08-28T15:04:03.185711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/working/conv_results.pkl', 'rb') as f:\n    results = pickle.load(f)\n    [\n    conv_history , test_loss , test_accuracy\n    ] = results\n\n\n# Print the training history\nprint(\"\\nTraining History:\")\nprint(\"=\" * 50)\nprint(\"Training Loss over Epochs: \", conv_history.history['loss'])\nprint(\"Validation Loss over Epochs: \", conv_history.history['val_loss'])\nprint(\"Training Accuracy over Epochs: \", conv_history.history['accuracy'])\nprint(\"Validation Accuracy over Epochs: \", conv_history.history['val_accuracy'])\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(\"=\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T16:13:19.386053Z","iopub.execute_input":"2025-07-15T16:13:19.386365Z","iopub.status.idle":"2025-07-15T16:13:19.760694Z","shell.execute_reply.started":"2025-07-15T16:13:19.386341Z","shell.execute_reply":"2025-07-15T16:13:19.759500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_random_seed(seed=42):\n    \"\"\"Set random seed for reproducibility.\"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)  # Fix hash-based randomness\n    random.seed(seed)  # Python's built-in random module\n    np.random.seed(seed)  # NumPy random seed\n    tf.random.set_seed(seed)  # TensorFlow random seed\n\n    # Optional: Enable GPU determinism for reproducibility\n    tf.config.experimental.enable_op_determinism()\n\n# Set seed before training\nset_random_seed(42)\n\ndef build_autoencoder_less_nodes(input_shape):\n    \"\"\"Build a vanilla autoencoder with fewer nodes.\"\"\"\n    print(f\"Input shape: {input_shape}\")\n\n    # Encoder\n    encoder_input = tf.keras.Input(shape=(112, 112, 3), name=\"encoder_input\")\n    flat_input = tf.keras.layers.Flatten(name=\"flatten_input\")(encoder_input)\n    dense_128_a = tf.keras.layers.Dense(128, activation='relu', name=\"dense_128_a\")(flat_input)\n    dense_128_b = tf.keras.layers.Dense(128, activation='relu', name=\"dense_128_b\")(dense_128_a)\n    dense_64 = tf.keras.layers.Dense(64, activation='relu', name=\"dense_64\")(dense_128_b)\n    latent_layer = tf.keras.layers.Dense(64, activation='relu', name=\"latent_layer\")(dense_64)\n\n    # Decoder\n    decoder_dense_64 = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_dense_64\")(latent_layer)\n    decoder_dense_128_a = tf.keras.layers.Dense(128, activation='relu', name=\"decoder_dense_128_a\")(decoder_dense_64)\n    decoder_dense_128_b = tf.keras.layers.Dense(128, activation='relu', name=\"decoder_dense_128_b\")(decoder_dense_128_a)\n    output_flat = tf.keras.layers.Dense(np.prod(input_shape), activation='linear', name=\"output_flat\")(decoder_dense_128_b)\n    output_reshaped = tf.keras.layers.Reshape(input_shape, name=\"output_reshaped\")(output_flat)\n\n    encoder = tf.keras.Model(encoder_input, latent_layer, name=\"Encoder\")\n    autoencoder = tf.keras.Model(inputs=encoder_input, outputs=output_reshaped, name=\"Autoencoder_Less_Nodes\")\n\n    return autoencoder ,encoder\n\ndef build_autoencoder_longer(input_shape):\n    \"\"\"Build a vanilla autoencoder with more layers.\"\"\"\n    print(f\"Input shape: {input_shape}\")\n\n    # Encoder\n    encoder_input = tf.keras.Input(shape=input_shape, name=\"encoder_input\")\n    flat_input = tf.keras.layers.Flatten(name=\"flatten_input\")(encoder_input)\n    dense_256 = tf.keras.layers.Dense(256, activation='relu', name=\"dense_256\")(flat_input)\n    dense_128 = tf.keras.layers.Dense(128, activation='relu', name=\"dense_128\")(dense_256)\n    dense_64 = tf.keras.layers.Dense(64, activation='relu', name=\"dense_64\")(dense_128)\n    latent_layer = tf.keras.layers.Dense(64, activation='relu', name=\"latent_layer\")(dense_64)\n\n    # Decoder\n    decoder_dense_64 = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_dense_64\")(latent_layer)\n    decoder_dense_128 = tf.keras.layers.Dense(128, activation='relu', name=\"decoder_dense_128\")(decoder_dense_64)\n    decoder_dense_256 = tf.keras.layers.Dense(256, activation='relu', name=\"decoder_dense_256\")(decoder_dense_128)\n    output_flat = tf.keras.layers.Dense(np.prod(input_shape), activation='sigmoid', name=\"output_flat\")(decoder_dense_256)\n    output_reshaped = tf.keras.layers.Reshape(input_shape, name=\"output_reshaped\")(output_flat)\n\n    encoder = tf.keras.Model(encoder_input, latent_layer, name=\"Encoder\")\n    autoencoder = tf.keras.Model(inputs=encoder_input, outputs=output_reshaped, name=\"Autoencoder_Longer\")\n\n\n    return autoencoder , encoder\n\ndef build_autoencoder(input_shape):\n    \"\"\"Build a basic vanilla autoencoder.\"\"\"\n    print(f\"Input shape: {input_shape}\")\n\n    # Encoder\n    encoder_input = tf.keras.Input(shape=input_shape, name=\"encoder_input\")\n    flat_input = tf.keras.layers.Flatten(name=\"flatten_input\")(encoder_input)\n    dense_256 = tf.keras.layers.Dense(256, activation='relu', name=\"dense_256\")(flat_input)\n    dense_64 = tf.keras.layers.Dense(64, activation='relu', name=\"dense_64\")(dense_256)\n    latent_layer = tf.keras.layers.Dense(64, activation='relu', name=\"latent_layer\")(dense_64)\n\n    # Decoder\n    decoder_dense_64 = tf.keras.layers.Dense(64, activation='relu', name=\"decoder_dense_64\")(latent_layer)\n    decoder_dense_256 = tf.keras.layers.Dense(256, activation='relu', name=\"decoder_dense_256\")(decoder_dense_64)\n    output_flat = tf.keras.layers.Dense(np.prod(input_shape), activation='sigmoid', name=\"output_flat\")(decoder_dense_256)\n    output_reshaped = tf.keras.layers.Reshape(input_shape, name=\"output_reshaped\")(output_flat)\n\n    encoder = tf.keras.Model(encoder_input, latent_layer, name=\"Encoder\")\n    autoencoder = tf.keras.Model(inputs=encoder_input, outputs=output_reshaped, name=\"Basic_Autoencoder\")\n\n    return autoencoder , encoder\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T01:21:25.656558Z","iopub.execute_input":"2024-12-28T01:21:25.656877Z","iopub.status.idle":"2024-12-28T01:21:25.843199Z","shell.execute_reply.started":"2024-12-28T01:21:25.656853Z","shell.execute_reply":"2024-12-28T01:21:25.842137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set seed for reproducibility\nset_random_seed(42)\n\n# Part 1: Autoencoder with fewer nodes\ninput_shape = (112, 112, 3)\nprint(\"Training Autoencoder with Fewer Nodes\")\nautoencoder_less, encoder_less = build_autoencoder_less_nodes(input_shape=input_shape)  # Function name adjusted\nautoencoder_less.compile(optimizer='adam', loss='mse', metrics=['accuracy'])  # Mean squared error loss\n\n# Train the autoencoder\nepochs = 5\nhistory_1 = autoencoder_less.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=epochs,\n    verbose=1\n)\n\n# Evaluate the model on the test set\ntest_loss_1 = autoencoder_less.evaluate(test_dataset)\nprint(f\"Test Loss (Less Nodes): {test_loss_1[0]:.4f}\")\nprint(f\"Test Accuracy (Less Nodes): {test_loss_1[1]:.4f}\")\n\n# Part 2: Autoencoder with more nodes\nset_random_seed(42)\nprint(\"\\nTraining Autoencoder with More Nodes\")\nautoencoder_long, encoder_long = build_autoencoder_longer(input_shape=input_shape)  # Function name adjusted\nautoencoder_long.compile(optimizer='adam', loss='mse', metrics=['accuracy'])  # Mean squared error loss\n\n# Train the autoencoder\nepochs = 5\nhistory_2 = autoencoder_long.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=epochs,\n    verbose=1\n)\n\n# Evaluate the model on the test set\ntest_loss_2 = autoencoder_long.evaluate(test_dataset)\nprint(f\"Test Loss (More Nodes): {test_loss_2[0]:.4f}\")\nprint(f\"Test Accuracy (More Nodes): {test_loss_2[1]:.4f}\")\n\n# Part 3: Original Autoencoder\nset_random_seed(42)\nprint(\"\\nTraining Original Autoencoder\")\nautoencoder_orig, encoder_orig = build_autoencoder(input_shape=input_shape)  # Function name adjusted\nautoencoder_orig.compile(optimizer='adam', loss='mse', metrics=['accuracy'])  # Mean squared error loss\n\n# Train the autoencoder\nepochs = 5\nhistory_3 = autoencoder_orig.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=epochs,\n    verbose=1\n)\n\n# Evaluate the model on the test set\ntest_loss_3 = autoencoder_orig.evaluate(test_dataset)\nprint(f\"Test Loss (Original): {test_loss_3[0]:.4f}\")\nprint(f\"Test Accuracy (Original): {test_loss_3[1]:.4f}\")\n\n\n# Save the history and test_loss objects\nresults = [\n    history_1, history_2, history_3,\n    test_loss_1, test_loss_2, test_loss_3\n]\n\n# Save the objects to a pickle file\nwith open('/kaggle/working/autoencoder_results.pkl', 'wb') as f:\n    pickle.dump(results, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T01:22:21.751689Z","iopub.execute_input":"2024-12-28T01:22:21.752053Z","iopub.status.idle":"2024-12-28T01:23:29.906234Z","shell.execute_reply.started":"2024-12-28T01:22:21.752005Z","shell.execute_reply":"2024-12-28T01:23:29.905306Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/working/autoencoder_results.pkl', 'rb') as f:\n    results = pickle.load(f)\n    [\n    history_1, history_2, history_3,\n    test_loss_1, test_loss_2, test_loss_3\n    ] = results\n\n# Print the training history\nprint(\"\\nSummary of Results:\")\nprint(\"=\" * 50)\nprint(\"Autoencoder with Fewer Nodes:\")\nprint(f\"Training Loss: {history_1.history['loss']}\")\nprint(f\"Validation Loss: {history_1.history['val_loss']}\")\nprint(f\"Training Accuracy: {history_1.history['accuracy']}\")\nprint(f\"Validation Accuracy: {history_1.history['val_accuracy']}\")\nprint(f\"Test Loss: {test_loss_1[0]:.4f}\")\nprint(f\"Test Accuracy: {test_loss_1[1]:.4f}\")\n\nprint(\"\\nAutoencoder with More Nodes:\")\nprint(f\"Training Loss: {history_2.history['loss']}\")\nprint(f\"Validation Loss: {history_2.history['val_loss']}\")\nprint(f\"Training Accuracy: {history_2.history['accuracy']}\")\nprint(f\"Validation Accuracy: {history_2.history['val_accuracy']}\")\nprint(f\"Test Loss: {test_loss_2[0]:.4f}\")\nprint(f\"Test Accuracy: {test_loss_2[1]:.4f}\")\n\nprint(\"\\nOriginal Autoencoder:\")\nprint(f\"Training Loss: {history_3.history['loss']}\")\nprint(f\"Validation Loss: {history_3.history['val_loss']}\")\nprint(f\"Training Accuracy: {history_3.history['accuracy']}\")\nprint(f\"Validation Accuracy: {history_3.history['val_accuracy']}\")\nprint(f\"Test Loss: {test_loss_3[0]:.4f}\")\nprint(f\"Test Accuracy: {test_loss_3[1]:.4f}\")\nprint(\"=\" * 50)\n\n\n\nmetrics = [\n    (\"accuracy\", \"Training Accuracy\"), \n    (\"val_accuracy\", \"Validation Accuracy\"), \n    (\"loss\", \"Training Loss\"), \n    (\"val_loss\", \"Validation Loss\")\n]\nhistories = [history_1, history_2, history_3]\nplot_labels = [\"Fewer Nodes\", \"More Nodes\", \"Original\"]\nepochs = range(1, len(history_1.history['accuracy']) + 1)\n\n# Accuracy plot\nplt.figure(figsize=(5, 3))\nfor history, label in zip(histories, plot_labels):\n    for metric, description in metrics[:2]:  # Accuracy metrics\n        linestyle = '--' if 'Validation' in description else '-'\n        plt.plot(epochs, history.history[metric], label=f\"{description} ({label})\", linestyle=linestyle)\n\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Loss plot\nplt.figure(figsize=(5, 3))\nfor history, label in zip(histories, labels):\n    for metric, description in metrics[2:]:  # Loss metrics\n        linestyle = '--' if 'Validation' in description else '-'\n        plt.plot(epochs, history.history[metric], label=f\"{description} ({label})\", linestyle=linestyle)\n\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T01:32:28.39315Z","iopub.execute_input":"2024-12-28T01:32:28.393473Z","iopub.status.idle":"2024-12-28T01:32:35.408537Z","shell.execute_reply.started":"2024-12-28T01:32:28.393448Z","shell.execute_reply":"2024-12-28T01:32:35.407595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming `images` is your dataset of shape (M, 112, 112, 3)\n# M is the number of images\ndef eigenfaces(images, num_components=50):\n    M, h, w, c = images.shape\n    \n    # Step 1: Flatten images\n    flattened_images = images.reshape(M, -1)  # Shape: (M, 37632)\n    \n    # Step 2: Normalize the data\n    mean_face = np.mean(flattened_images, axis=0)\n    centered_images = flattened_images - mean_face\n    \n    # Step 3: Apply PCA\n    pca = PCA(n_components=num_components)\n    pca.fit(centered_images)\n    eigenfaces = pca.components_  # Principal components\n    \n    # Step 4: Project the dataset onto the PCA subspace\n    projections = pca.transform(centered_images)\n    \n    return eigenfaces, projections, mean_face\n\n# Example usage:\n# Convert dataset to grayscale (optional)\ndef convert_to_grayscale(images):\n    return np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in images])\n\n# Your dataset\n# images = load_your_images()  # Load images in shape (M, 112, 112, 3)\n\nimages = convert_to_grayscale(normalized_images).reshape(-1, 112, 112, 1)\n\n# Run Eigenfaces\neigenfaces, projections, mean_face = eigenfaces(images, num_components=50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T01:33:09.832318Z","iopub.execute_input":"2024-12-28T01:33:09.832674Z","iopub.status.idle":"2024-12-28T01:33:15.719138Z","shell.execute_reply.started":"2024-12-28T01:33:09.832642Z","shell.execute_reply":"2024-12-28T01:33:15.71786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_evaluate_model(X, labels, num_epochs):\n    # Flatten images to fit into a neural network\n    X_flat = X.reshape(X.shape[0], -1)  # Flatten images from 50x37 to 1850 vector\n\n    # Encode labels as one-hot vectors\n    label_encoder = LabelEncoder()\n    y_encoded = label_encoder.fit_transform(labels[:, 0])\n    y_one_hot = tf.keras.utils.to_categorical(y_encoded)\n\n    # Step 3: Split data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X_flat, y_one_hot, test_size=0.2, random_state=42)\n\n    # Step 4: Build the neural network model\n    model = Sequential([\n        tf.keras.Input(shape=(X_train.shape[1],)),  # Define input shape explicitly\n        Dense(1024, activation='relu'),\n        # Dropout(0.2),\n        Dense(512, activation='relu'),\n        # Dropout(0.2),\n        Dense(128, activation='relu'),\n        Dense(y_one_hot.shape[1], activation='softmax')\n    ])\n\n    # Step 5: Compile the model\n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Step 6: Train the model and store accuracy and loss\n    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=256, validation_data=(X_test, y_test))\n\n    # Store the accuracy and loss for each epoch\n    train_accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    # Step 7: Evaluate the model\n    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n    # Step 8: Make predictions\n    test_image = X_test[0].reshape(1, -1)  # Flatten image\n    prediction = model.predict(test_image)\n    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n    print(f\"Predicted label: {predicted_label[0]}\")\n    \n    # Return the lists of accuracies and losses for further visualization\n    return train_accuracy, val_accuracy, train_loss, val_loss, test_accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Method 1: Using encoder_less\n# X_encoder_less = encoder_less.predict(normalized_images, batch_size=32, verbose=1)\n# train_accuracy1, val_accuracy1, train_loss1, val_loss1, test_accuracy1 = train_and_evaluate_model(X_encoder_less, labels, 30)\n\n# # Method 2: Using encoder_long\n# X_encoder_long = encoder_long.predict(normalized_images, batch_size=32, verbose=1)\n# train_accuracy2, val_accuracy2, train_loss2, val_loss2, test_accuracy2 = train_and_evaluate_model(X_encoder_long, labels, 30)\n\n# # Method 3: Using encoder_orig\n# X_encoder_orig = encoder_orig.predict(normalized_images, batch_size=32, verbose=1)\n# train_accuracy3, val_accuracy3, train_loss3, val_loss3, test_accuracy3 = train_and_evaluate_model(X_encoder_orig, labels, 30)\n\n# Method 4: Using conv_encoder\ntrain_lables = lables[train_indices]\nval_lables = lables[val_indices]\ntest_lables = lables[test_indices]\ntrain_lables_new = np.concatenate([train_lables,val_lables,test_lables], axis=0)\ntrain_data_new = np.concatenate([train_data_norm, val_data_norm, test_data_norm], axis=0)\nX_conv_encoder = conv_encoder.predict(train_data_new, batch_size=256, verbose=1)\n\ntrain_accuracy4, val_accuracy4, train_loss4, val_loss4, test_accuracy4 = train_and_evaluate_model(X_conv_encoder, train_lables_new, 30)\n\n# # Method 5: Using projections\n# train_accuracy5, val_accuracy5, train_loss5, val_loss5, test_accuracy5 = train_and_evaluate_model(projections, labels, 30)\n\nresults = [\n    [train_accuracy4, val_accuracy4, train_loss4, val_loss4, test_accuracy4],\n    # [train_accuracy5, val_accuracy5, train_loss5, val_loss5, test_accuracy5],\n]\n\n# Save to pickle file\nwith open('model_results.pkl', 'wb') as f:\n    pickle.dump(results, f)\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load results from pickle file\nwith open('model_results.pkl', 'rb') as f:\n    results = pickle.load(f)\n    [\n    [train_accuracy1, val_accuracy1, train_loss1, val_loss1, test_accuracy1],\n    [train_accuracy2, val_accuracy2, train_loss2, val_loss2, test_accuracy2],\n    [train_accuracy3, val_accuracy3, train_loss3, val_loss3, test_accuracy3],\n    [train_accuracy4, val_accuracy4, train_loss4, val_loss4, test_accuracy4],\n    [train_accuracy5, val_accuracy5, train_loss5, val_loss5, test_accuracy5],\n    ] = results\n\n\n# Visualization of Results\n\n# Create a table with final accuracy of each method\nmethods = ['encoder_less', 'encoder_long', 'encoder_orig', 'conv_encoder', 'projections']\naccuracies = [test_accuracy1, test_accuracy2, test_accuracy3, test_accuracy4, test_accuracy5]\n\naccuracy_df = pd.DataFrame({'Method': methods, 'Test Accuracy': accuracies})\nprint(\"\\nAccuracy Comparison Table:\")\nprint(accuracy_df.to_string(index=False))\n\n# Plot the Accuracy and Loss for each method\nplt.figure(figsize=(15, 6))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(train_accuracy1, label='Encoder Less Train')\nplt.plot(val_accuracy1, label='Encoder Less Validation')\nplt.plot(train_accuracy2, label='Encoder Long Train')\nplt.plot(val_accuracy2, label='Encoder Long Validation')\nplt.plot(train_accuracy3, label='Encoder Orig Train')\nplt.plot(val_accuracy3, label='Encoder Orig Validation')\nplt.plot(train_accuracy4, label='Conv Encoder Train')\nplt.plot(val_accuracy4, label='Conv Encoder Validation')\nplt.plot(train_accuracy5, label='Projections Train')\nplt.plot(val_accuracy5, label='Projections Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Model Accuracy per Epoch')\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(train_loss1, label='Encoder Less Train Loss')\nplt.plot(val_loss1, label='Encoder Less Validation Loss')\nplt.plot(train_loss2, label='Encoder Long Train Loss')\nplt.plot(val_loss2, label='Encoder Long Validation Loss')\nplt.plot(train_loss3, label='Encoder Orig Train Loss')\nplt.plot(val_loss3, label='Encoder Orig Validation Loss')\nplt.plot(train_loss4, label='Conv Encoder Train Loss')\nplt.plot(val_loss4, label='Conv Encoder Validation Loss')\nplt.plot(train_loss5, label='Projections Train Loss')\nplt.plot(val_loss5, label='Projections Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Model Loss per Epoch')\n\n# Display the plots\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T01:35:10.241213Z","iopub.execute_input":"2024-12-28T01:35:10.241523Z","iopub.status.idle":"2024-12-28T01:35:11.083412Z","shell.execute_reply.started":"2024-12-28T01:35:10.241497Z","shell.execute_reply":"2024-12-28T01:35:11.08246Z"}},"outputs":[],"execution_count":null}]}